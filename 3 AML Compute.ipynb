{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure ML Compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/retkowsky/images/blob/master/AzureMLservicebanniere.png?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation:<br>\n",
    "https://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-target <br>\n",
    "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-set-up-training-targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Azure Machine Learning Compute** is a **managed-compute infrastructure** that allows the user to easily create a single or multi-node compute. The compute is created within your workspace region as a resource that can be shared with other users in your workspace. The compute **scales up automatically when a job is submitted**, and can be put in an Azure Virtual Network. The compute executes in a containerized environment and packages your model dependencies in a **Docker container**.\n",
    "\n",
    "You can use Azure Machine Learning Compute to distribute the training process across a cluster of **CPU or GPU** compute nodes in the cloud. For more information on the VM sizes that include GPUs, see GPU-optimized virtual machine sizes.\n",
    "\n",
    "Azure Machine Learning Compute has default limits, such as the number of cores that can be allocated. For more information, see Manage and request quotas for Azure resources.\n",
    "\n",
    "You can create an Azure Machine Learning compute environment **on demand** when you schedule a run, or as a **persistent resource**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-13 09:35:07.147158\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "print(now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version Azure ML : 1.15.0\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "print(\"Version Azure ML :\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Workspace\n",
    "\n",
    "Initialize a workspace object from persisted configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "create workspace"
    ]
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Expérimentation\n",
    "\n",
    "**Experiment** is a logical container in an Azure ML Workspace. It hosts run records which can include run metrics and output artifacts from your experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "experiment_name = 'Workshop-amlcompute'\n",
    "experiment = Experiment(workspace = ws, name = experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Introduction AmlCompute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-set-up-training-targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Liste des compute servers définis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute instances in your workspace Azure ML:\n",
      "- monclustergpu\n",
      "- nbookinstance\n",
      "- monclustercpu\n",
      "- cpucluster\n",
      "- cpuclusterd2\n",
      "- clustergpu\n"
     ]
    }
   ],
   "source": [
    "print(\"Compute instances in your workspace Azure ML:\")\n",
    "cts = ws.compute_targets\n",
    "for ct in cts:\n",
    "    print('-', ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Liste serveurs AML Compute disponibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Standard_D1_v2',\n",
       "  'vCPUs': 1,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 3.5,\n",
       "  'maxResourceVolumeMB': 51200},\n",
       " {'name': 'Standard_D2_v2',\n",
       "  'vCPUs': 2,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 7.0,\n",
       "  'maxResourceVolumeMB': 102400},\n",
       " {'name': 'Standard_D3_v2',\n",
       "  'vCPUs': 4,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 14.0,\n",
       "  'maxResourceVolumeMB': 204800},\n",
       " {'name': 'Standard_D4_v2',\n",
       "  'vCPUs': 8,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 28.0,\n",
       "  'maxResourceVolumeMB': 409600},\n",
       " {'name': 'Standard_D11_v2',\n",
       "  'vCPUs': 2,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 14.0,\n",
       "  'maxResourceVolumeMB': 102400},\n",
       " {'name': 'Standard_D12_v2',\n",
       "  'vCPUs': 4,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 28.0,\n",
       "  'maxResourceVolumeMB': 204800},\n",
       " {'name': 'Standard_D13_v2',\n",
       "  'vCPUs': 8,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 56.0,\n",
       "  'maxResourceVolumeMB': 409600},\n",
       " {'name': 'Standard_D14_v2',\n",
       "  'vCPUs': 16,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 112.0,\n",
       "  'maxResourceVolumeMB': 819200},\n",
       " {'name': 'Standard_DS1_v2',\n",
       "  'vCPUs': 1,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 3.5,\n",
       "  'maxResourceVolumeMB': 7168},\n",
       " {'name': 'Standard_DS2_v2',\n",
       "  'vCPUs': 2,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 7.0,\n",
       "  'maxResourceVolumeMB': 14336},\n",
       " {'name': 'Standard_DS3_v2',\n",
       "  'vCPUs': 4,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 14.0,\n",
       "  'maxResourceVolumeMB': 28672},\n",
       " {'name': 'Standard_DS4_v2',\n",
       "  'vCPUs': 8,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 28.0,\n",
       "  'maxResourceVolumeMB': 57344},\n",
       " {'name': 'Standard_DS5_v2',\n",
       "  'vCPUs': 16,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 56.0,\n",
       "  'maxResourceVolumeMB': 114688},\n",
       " {'name': 'Standard_DS11_v2',\n",
       "  'vCPUs': 2,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 14.0,\n",
       "  'maxResourceVolumeMB': 28672},\n",
       " {'name': 'Standard_DS12_v2',\n",
       "  'vCPUs': 4,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 28.0,\n",
       "  'maxResourceVolumeMB': 57344},\n",
       " {'name': 'Standard_DS13_v2',\n",
       "  'vCPUs': 8,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 56.0,\n",
       "  'maxResourceVolumeMB': 114688},\n",
       " {'name': 'Standard_DS14_v2',\n",
       "  'vCPUs': 16,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 112.0,\n",
       "  'maxResourceVolumeMB': 229376},\n",
       " {'name': 'Standard_D2_v3',\n",
       "  'vCPUs': 2,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 8.0,\n",
       "  'maxResourceVolumeMB': 51200},\n",
       " {'name': 'Standard_D4_v3',\n",
       "  'vCPUs': 4,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 16.0,\n",
       "  'maxResourceVolumeMB': 102400},\n",
       " {'name': 'Standard_D8_v3',\n",
       "  'vCPUs': 8,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 32.0,\n",
       "  'maxResourceVolumeMB': 204800},\n",
       " {'name': 'Standard_D16_v3',\n",
       "  'vCPUs': 16,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 64.0,\n",
       "  'maxResourceVolumeMB': 409600},\n",
       " {'name': 'Standard_D32_v3',\n",
       "  'vCPUs': 32,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 128.0,\n",
       "  'maxResourceVolumeMB': 819200},\n",
       " {'name': 'Standard_D64_v3',\n",
       "  'vCPUs': 64,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 256.0,\n",
       "  'maxResourceVolumeMB': 1638400},\n",
       " {'name': 'Standard_D2s_v3',\n",
       "  'vCPUs': 2,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 8.0,\n",
       "  'maxResourceVolumeMB': 16384},\n",
       " {'name': 'Standard_D4s_v3',\n",
       "  'vCPUs': 4,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 16.0,\n",
       "  'maxResourceVolumeMB': 32768},\n",
       " {'name': 'Standard_D8s_v3',\n",
       "  'vCPUs': 8,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 32.0,\n",
       "  'maxResourceVolumeMB': 65536},\n",
       " {'name': 'Standard_D16s_v3',\n",
       "  'vCPUs': 16,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 64.0,\n",
       "  'maxResourceVolumeMB': 131072},\n",
       " {'name': 'Standard_D32s_v3',\n",
       "  'vCPUs': 32,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 128.0,\n",
       "  'maxResourceVolumeMB': 262144},\n",
       " {'name': 'Standard_D64s_v3',\n",
       "  'vCPUs': 64,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 256.0,\n",
       "  'maxResourceVolumeMB': 524288},\n",
       " {'name': 'Standard_M8-2ms',\n",
       "  'vCPUs': 8,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 218.75,\n",
       "  'maxResourceVolumeMB': 256000},\n",
       " {'name': 'Standard_M8-4ms',\n",
       "  'vCPUs': 8,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 218.75,\n",
       "  'maxResourceVolumeMB': 256000},\n",
       " {'name': 'Standard_M8ms',\n",
       "  'vCPUs': 8,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 218.75,\n",
       "  'maxResourceVolumeMB': 256000},\n",
       " {'name': 'Standard_M16-4ms',\n",
       "  'vCPUs': 16,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 437.5,\n",
       "  'maxResourceVolumeMB': 512000},\n",
       " {'name': 'Standard_M16-8ms',\n",
       "  'vCPUs': 16,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 437.5,\n",
       "  'maxResourceVolumeMB': 512000},\n",
       " {'name': 'Standard_M16ms',\n",
       "  'vCPUs': 16,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 437.5,\n",
       "  'maxResourceVolumeMB': 512000},\n",
       " {'name': 'Standard_M32-8ms',\n",
       "  'vCPUs': 32,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 875.0,\n",
       "  'maxResourceVolumeMB': 1024000},\n",
       " {'name': 'Standard_M32-16ms',\n",
       "  'vCPUs': 32,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 875.0,\n",
       "  'maxResourceVolumeMB': 1024000},\n",
       " {'name': 'Standard_M32ls',\n",
       "  'vCPUs': 32,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 256.0,\n",
       "  'maxResourceVolumeMB': 1024000},\n",
       " {'name': 'Standard_M32ms',\n",
       "  'vCPUs': 32,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 875.0,\n",
       "  'maxResourceVolumeMB': 1024000},\n",
       " {'name': 'Standard_M32ts',\n",
       "  'vCPUs': 32,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 192.0,\n",
       "  'maxResourceVolumeMB': 1024000},\n",
       " {'name': 'Standard_M64-16ms',\n",
       "  'vCPUs': 64,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 1750.0,\n",
       "  'maxResourceVolumeMB': 2048000},\n",
       " {'name': 'Standard_M64-32ms',\n",
       "  'vCPUs': 64,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 1750.0,\n",
       "  'maxResourceVolumeMB': 2048000},\n",
       " {'name': 'Standard_M64ls',\n",
       "  'vCPUs': 64,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 512.0,\n",
       "  'maxResourceVolumeMB': 2048000},\n",
       " {'name': 'Standard_M64ms',\n",
       "  'vCPUs': 64,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 1750.0,\n",
       "  'maxResourceVolumeMB': 2048000},\n",
       " {'name': 'Standard_M64s',\n",
       "  'vCPUs': 64,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 1000.0,\n",
       "  'maxResourceVolumeMB': 2048000},\n",
       " {'name': 'Standard_M128-32ms',\n",
       "  'vCPUs': 128,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 3800.0,\n",
       "  'maxResourceVolumeMB': 4096000},\n",
       " {'name': 'Standard_M128-64ms',\n",
       "  'vCPUs': 128,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 3800.0,\n",
       "  'maxResourceVolumeMB': 4096000},\n",
       " {'name': 'Standard_M128ms',\n",
       "  'vCPUs': 128,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 3800.0,\n",
       "  'maxResourceVolumeMB': 4096000},\n",
       " {'name': 'Standard_M128s',\n",
       "  'vCPUs': 128,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 2000.0,\n",
       "  'maxResourceVolumeMB': 4096000},\n",
       " {'name': 'Standard_M64',\n",
       "  'vCPUs': 64,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 1000.0,\n",
       "  'maxResourceVolumeMB': 8192000},\n",
       " {'name': 'Standard_M64m',\n",
       "  'vCPUs': 64,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 1750.0,\n",
       "  'maxResourceVolumeMB': 8192000},\n",
       " {'name': 'Standard_M128',\n",
       "  'vCPUs': 128,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 2000.0,\n",
       "  'maxResourceVolumeMB': 16384000},\n",
       " {'name': 'Standard_M128m',\n",
       "  'vCPUs': 128,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 3800.0,\n",
       "  'maxResourceVolumeMB': 16384000},\n",
       " {'name': 'Standard_D1',\n",
       "  'vCPUs': 1,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 3.5,\n",
       "  'maxResourceVolumeMB': 51200},\n",
       " {'name': 'Standard_D2',\n",
       "  'vCPUs': 2,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 7.0,\n",
       "  'maxResourceVolumeMB': 102400},\n",
       " {'name': 'Standard_D3',\n",
       "  'vCPUs': 4,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 14.0,\n",
       "  'maxResourceVolumeMB': 204800},\n",
       " {'name': 'Standard_D4',\n",
       "  'vCPUs': 8,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 28.0,\n",
       "  'maxResourceVolumeMB': 409600},\n",
       " {'name': 'Standard_D11',\n",
       "  'vCPUs': 2,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 14.0,\n",
       "  'maxResourceVolumeMB': 102400},\n",
       " {'name': 'Standard_D12',\n",
       "  'vCPUs': 4,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 28.0,\n",
       "  'maxResourceVolumeMB': 204800},\n",
       " {'name': 'Standard_D13',\n",
       "  'vCPUs': 8,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 56.0,\n",
       "  'maxResourceVolumeMB': 409600},\n",
       " {'name': 'Standard_D14',\n",
       "  'vCPUs': 16,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 112.0,\n",
       "  'maxResourceVolumeMB': 819200},\n",
       " {'name': 'Standard_HB120rs_v2',\n",
       "  'vCPUs': 120,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 468.75,\n",
       "  'maxResourceVolumeMB': 960000},\n",
       " {'name': 'Standard_D15_v2',\n",
       "  'vCPUs': 20,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 140.0,\n",
       "  'maxResourceVolumeMB': 1024000},\n",
       " {'name': 'Standard_DS15_v2',\n",
       "  'vCPUs': 20,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 140.0,\n",
       "  'maxResourceVolumeMB': 286720},\n",
       " {'name': 'Standard_F2s_v2',\n",
       "  'vCPUs': 2,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 4.0,\n",
       "  'maxResourceVolumeMB': 16384},\n",
       " {'name': 'Standard_F4s_v2',\n",
       "  'vCPUs': 4,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 8.0,\n",
       "  'maxResourceVolumeMB': 32768},\n",
       " {'name': 'Standard_F8s_v2',\n",
       "  'vCPUs': 8,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 16.0,\n",
       "  'maxResourceVolumeMB': 65536},\n",
       " {'name': 'Standard_F16s_v2',\n",
       "  'vCPUs': 16,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 32.0,\n",
       "  'maxResourceVolumeMB': 131072},\n",
       " {'name': 'Standard_F32s_v2',\n",
       "  'vCPUs': 32,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 64.0,\n",
       "  'maxResourceVolumeMB': 262144},\n",
       " {'name': 'Standard_F64s_v2',\n",
       "  'vCPUs': 64,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 128.0,\n",
       "  'maxResourceVolumeMB': 524288},\n",
       " {'name': 'Standard_F72s_v2',\n",
       "  'vCPUs': 72,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 144.0,\n",
       "  'maxResourceVolumeMB': 589824},\n",
       " {'name': 'Standard_NC6s_v3',\n",
       "  'vCPUs': 6,\n",
       "  'gpus': 1,\n",
       "  'memoryGB': 112.0,\n",
       "  'maxResourceVolumeMB': 344064},\n",
       " {'name': 'Standard_NC12s_v3',\n",
       "  'vCPUs': 12,\n",
       "  'gpus': 2,\n",
       "  'memoryGB': 224.0,\n",
       "  'maxResourceVolumeMB': 688128},\n",
       " {'name': 'Standard_NC24rs_v3',\n",
       "  'vCPUs': 24,\n",
       "  'gpus': 4,\n",
       "  'memoryGB': 448.0,\n",
       "  'maxResourceVolumeMB': 1376256},\n",
       " {'name': 'Standard_NC24s_v3',\n",
       "  'vCPUs': 24,\n",
       "  'gpus': 4,\n",
       "  'memoryGB': 448.0,\n",
       "  'maxResourceVolumeMB': 1376256},\n",
       " {'name': 'Standard_NV6',\n",
       "  'vCPUs': 6,\n",
       "  'gpus': 1,\n",
       "  'memoryGB': 56.0,\n",
       "  'maxResourceVolumeMB': 389120},\n",
       " {'name': 'Standard_NV12',\n",
       "  'vCPUs': 12,\n",
       "  'gpus': 2,\n",
       "  'memoryGB': 112.0,\n",
       "  'maxResourceVolumeMB': 696320},\n",
       " {'name': 'Standard_NV24',\n",
       "  'vCPUs': 24,\n",
       "  'gpus': 4,\n",
       "  'memoryGB': 224.0,\n",
       "  'maxResourceVolumeMB': 1474560},\n",
       " {'name': 'Standard_NV12s_v3',\n",
       "  'vCPUs': 12,\n",
       "  'gpus': 1,\n",
       "  'memoryGB': 112.0,\n",
       "  'maxResourceVolumeMB': 344064},\n",
       " {'name': 'Standard_NV24s_v3',\n",
       "  'vCPUs': 24,\n",
       "  'gpus': 2,\n",
       "  'memoryGB': 224.0,\n",
       "  'maxResourceVolumeMB': 688128},\n",
       " {'name': 'Standard_NV48s_v3',\n",
       "  'vCPUs': 48,\n",
       "  'gpus': 4,\n",
       "  'memoryGB': 448.0,\n",
       "  'maxResourceVolumeMB': 1376256},\n",
       " {'name': 'Standard_NC6',\n",
       "  'vCPUs': 6,\n",
       "  'gpus': 1,\n",
       "  'memoryGB': 56.0,\n",
       "  'maxResourceVolumeMB': 389120},\n",
       " {'name': 'Standard_NC12',\n",
       "  'vCPUs': 12,\n",
       "  'gpus': 2,\n",
       "  'memoryGB': 112.0,\n",
       "  'maxResourceVolumeMB': 696320},\n",
       " {'name': 'Standard_NC24',\n",
       "  'vCPUs': 24,\n",
       "  'gpus': 4,\n",
       "  'memoryGB': 224.0,\n",
       "  'maxResourceVolumeMB': 1474560},\n",
       " {'name': 'Standard_NC24r',\n",
       "  'vCPUs': 24,\n",
       "  'gpus': 4,\n",
       "  'memoryGB': 224.0,\n",
       "  'maxResourceVolumeMB': 1474560},\n",
       " {'name': 'Standard_ND6s',\n",
       "  'vCPUs': 6,\n",
       "  'gpus': 1,\n",
       "  'memoryGB': 112.0,\n",
       "  'maxResourceVolumeMB': 344064},\n",
       " {'name': 'Standard_ND12s',\n",
       "  'vCPUs': 12,\n",
       "  'gpus': 2,\n",
       "  'memoryGB': 224.0,\n",
       "  'maxResourceVolumeMB': 688128},\n",
       " {'name': 'Standard_ND24rs',\n",
       "  'vCPUs': 24,\n",
       "  'gpus': 4,\n",
       "  'memoryGB': 448.0,\n",
       "  'maxResourceVolumeMB': 1376256},\n",
       " {'name': 'Standard_ND24s',\n",
       "  'vCPUs': 24,\n",
       "  'gpus': 4,\n",
       "  'memoryGB': 448.0,\n",
       "  'maxResourceVolumeMB': 1376256},\n",
       " {'name': 'Standard_ND40rs_v2',\n",
       "  'vCPUs': 40,\n",
       "  'gpus': 8,\n",
       "  'memoryGB': 672.0,\n",
       "  'maxResourceVolumeMB': 2969600},\n",
       " {'name': 'Standard_HC44rs',\n",
       "  'vCPUs': 44,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 327.83,\n",
       "  'maxResourceVolumeMB': 716800},\n",
       " {'name': 'Standard_NC6s_v2',\n",
       "  'vCPUs': 6,\n",
       "  'gpus': 1,\n",
       "  'memoryGB': 112.0,\n",
       "  'maxResourceVolumeMB': 344064},\n",
       " {'name': 'Standard_NC12s_v2',\n",
       "  'vCPUs': 12,\n",
       "  'gpus': 2,\n",
       "  'memoryGB': 224.0,\n",
       "  'maxResourceVolumeMB': 688128},\n",
       " {'name': 'Standard_NC24rs_v2',\n",
       "  'vCPUs': 24,\n",
       "  'gpus': 4,\n",
       "  'memoryGB': 448.0,\n",
       "  'maxResourceVolumeMB': 1376256},\n",
       " {'name': 'Standard_NC24s_v2',\n",
       "  'vCPUs': 24,\n",
       "  'gpus': 4,\n",
       "  'memoryGB': 448.0,\n",
       "  'maxResourceVolumeMB': 1376256}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "\n",
    "AmlCompute.supported_vmsizes(workspace = ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./train-on-amlcompute/train_aml.py'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "project_folder = './train-on-amlcompute'\n",
    "os.makedirs(project_folder, exist_ok=True)\n",
    "shutil.copy('train_aml.py', project_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright (c) Microsoft. All rights reserved.\n",
      "# Licensed under the MIT license.\n",
      "\n",
      "from sklearn.datasets import load_diabetes\n",
      "from sklearn.linear_model import Ridge\n",
      "from sklearn.metrics import mean_squared_error\n",
      "from sklearn.model_selection import train_test_split\n",
      "from azureml.core.run import Run\n",
      "from sklearn.externals import joblib\n",
      "import os\n",
      "import numpy as np\n",
      "\n",
      "os.makedirs('./outputs', exist_ok=True)\n",
      "\n",
      "X, y = load_diabetes(return_X_y=True)\n",
      "\n",
      "run = Run.get_context()\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
      "                                                    test_size=0.2,\n",
      "                                                    random_state=0)\n",
      "data = {\"train\": {\"X\": X_train, \"y\": y_train},\n",
      "        \"test\": {\"X\": X_test, \"y\": y_test}}\n",
      "\n",
      "# list of numbers from 0.0 to 1.0 with a 0.05 interval\n",
      "alphas = np.arange(0.0, 1.0, 0.05)\n",
      "\n",
      "for alpha in alphas:\n",
      "    # Use Ridge algorithm to create a regression model\n",
      "    reg = Ridge(alpha=alpha)\n",
      "    reg.fit(data[\"train\"][\"X\"], data[\"train\"][\"y\"])\n",
      "\n",
      "    preds = reg.predict(data[\"test\"][\"X\"])\n",
      "    mse = mean_squared_error(preds, data[\"test\"][\"y\"])\n",
      "    run.log('alpha', alpha)\n",
      "    run.log('mse', mse)\n",
      "\n",
      "    model_file_name = 'ridge_{0:.2f}.pkl'.format(alpha)\n",
      "    # save model in the outputs folder so it automatically get uploaded\n",
      "    with open(model_file_name, \"wb\") as file:\n",
      "        joblib.dump(value=reg, filename=os.path.join('./outputs/',\n",
      "                                                     model_file_name))\n",
      "\n",
      "    print('alpha is {0:.2f}, and mse is {1:0.2f}'.format(alpha, mse))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join('./train-on-amlcompute/train_aml.py'), 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version scikit-learn = 0.22.2.post1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print('Version scikit-learn =', sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "myenv = Environment(\"myenv\")\n",
    "\n",
    "myenv.docker.enabled = True\n",
    "\n",
    "myenv.python.conda_dependencies = CondaDependencies.create(conda_packages=['scikit-learn==0.20.3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Documentation : https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-set-up-training-targets#amlcompute<br>\n",
    "> Pricing : https://azure.microsoft.com/en-us/pricing/details/machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "sample-amlcompute-provision"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating\n",
      "Succeeded.................\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n",
      "CPU times: user 350 ms, sys: 32.2 ms, total: 383 ms\n",
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Nom\n",
    "cpu_cluster_name = \"cpuclusterd2v2\"\n",
    "\n",
    "try:\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n",
    "                                                           min_nodes = 1, #Mettre à 0 pour automatic shutdown\n",
    "                                                           max_nodes = 4)\n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "cpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nbookinstance\n",
      "monclustercpu\n",
      "cpucluster\n",
      "cpuclusterd2\n",
      "clustergpu\n",
      "cpuclusterd2v2\n"
     ]
    }
   ],
   "source": [
    "#Liste des compute servers disponibles\n",
    "listecomputeservers = ws.compute_targets\n",
    "for listesrv in listecomputeservers:\n",
    "    print(listesrv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'currentNodeCount': 1,\n",
       " 'targetNodeCount': 1,\n",
       " 'nodeStateCounts': {'preparingNodeCount': 0,\n",
       "  'runningNodeCount': 0,\n",
       "  'idleNodeCount': 1,\n",
       "  'unusableNodeCount': 0,\n",
       "  'leavingNodeCount': 0,\n",
       "  'preemptedNodeCount': 0},\n",
       " 'allocationState': 'Steady',\n",
       " 'allocationStateTransitionTime': '2020-10-13T09:39:58.164000+00:00',\n",
       " 'errors': None,\n",
       " 'creationTime': '2020-10-13T09:38:22.248494+00:00',\n",
       " 'modifiedTime': '2020-10-13T09:38:37.962911+00:00',\n",
       " 'provisioningState': 'Succeeded',\n",
       " 'provisioningStateTransitionTime': None,\n",
       " 'scaleSettings': {'minNodeCount': 1,\n",
       "  'maxNodeCount': 4,\n",
       "  'nodeIdleTimeBeforeScaleDown': 'PT120S'},\n",
       " 'vmPriority': 'Dedicated',\n",
       " 'vmSize': 'STANDARD_D2_V2'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_cluster.get_status().serialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'nodeId': 'tvmps_89a740fde66671fb6cbc40857379dc2c5b625d649f2027cfea1bbc63c0f024ee_d',\n",
       "  'port': 50000,\n",
       "  'publicIpAddress': '51.105.167.166',\n",
       "  'privateIpAddress': '10.0.0.4',\n",
       "  'nodeState': 'idle'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statut du compute server\n",
    "cpu_cluster.list_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Configuration et exécution du run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxrwxrwx 1 root root 1538 Oct 13 08:24 train_aml.py\r\n"
     ]
    }
   ],
   "source": [
    "# Fichier Python à exécuter\n",
    "!ls train_aml.py -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright (c) Microsoft. All rights reserved.\n",
      "# Licensed under the MIT license.\n",
      "\n",
      "from sklearn.datasets import load_diabetes\n",
      "from sklearn.linear_model import Ridge\n",
      "from sklearn.metrics import mean_squared_error\n",
      "from sklearn.model_selection import train_test_split\n",
      "from azureml.core.run import Run\n",
      "from sklearn.externals import joblib\n",
      "import os\n",
      "import numpy as np\n",
      "\n",
      "os.makedirs('./outputs', exist_ok=True)\n",
      "\n",
      "X, y = load_diabetes(return_X_y=True)\n",
      "\n",
      "run = Run.get_context()\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
      "                                                    test_size=0.2,\n",
      "                                                    random_state=0)\n",
      "data = {\"train\": {\"X\": X_train, \"y\": y_train},\n",
      "        \"test\": {\"X\": X_test, \"y\": y_test}}\n",
      "\n",
      "# list of numbers from 0.0 to 1.0 with a 0.05 interval\n",
      "alphas = np.arange(0.0, 1.0, 0.05)\n",
      "\n",
      "for alpha in alphas:\n",
      "    # Use Ridge algorithm to create a regression model\n",
      "    reg = Ridge(alpha=alpha)\n",
      "    reg.fit(data[\"train\"][\"X\"], data[\"train\"][\"y\"])\n",
      "\n",
      "    preds = reg.predict(data[\"test\"][\"X\"])\n",
      "    mse = mean_squared_error(preds, data[\"test\"][\"y\"])\n",
      "    run.log('alpha', alpha)\n",
      "    run.log('mse', mse)\n",
      "\n",
      "    model_file_name = 'ridge_{0:.2f}.pkl'.format(alpha)\n",
      "    # save model in the outputs folder so it automatically get uploaded\n",
      "    with open(model_file_name, \"wb\") as file:\n",
      "        joblib.dump(value=reg, filename=os.path.join('./outputs/',\n",
      "                                                     model_file_name))\n",
      "\n",
      "    print('alpha is {0:.2f}, and mse is {1:0.2f}'.format(alpha, mse))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join('train_aml.py'), 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "\n",
    "src = ScriptRunConfig(source_directory=project_folder, script='train_aml.py')\n",
    "\n",
    "# Set compute target to the one created in previous step\n",
    "src.run_config.target = cpu_cluster.name\n",
    "\n",
    "# Set environment\n",
    "src.run_config.environment = myenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de tags pour le run\n",
    "tagsdurun = {\"Type\": \"test\" , \"Langage\" : \"Python\" , \"Framework\" : \"Scikit-Learn\", \"Team\" : \"DataScience\" , \"Pays\" : \"France\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> C'est parti ! On exécute le run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>Workshop-amlcompute</td><td>Workshop-amlcompute_1602582161_46313f6a</td><td>azureml.scriptrun</td><td>Starting</td><td><a href=\"https://ml.azure.com/experiments/Workshop-amlcompute/runs/Workshop-amlcompute_1602582161_46313f6a?wsid=/subscriptions/70b8f39e-8863-49f7-b6ba-34a80799550c/resourcegroups/workshoplcl-rg/workspaces/workshoplcl\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: Workshop-amlcompute,\n",
       "Id: Workshop-amlcompute_1602582161_46313f6a,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Starting)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execution run\n",
    "run = experiment.submit(config=src, tags=tagsdurun)\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Widget disponible pour suivre l'avancement du run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e668937909264074804e5404342152b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/Workshop-amlcompute/runs/Workshop-amlcompute_1602582161_46313f6a?wsid=/subscriptions/70b8f39e-8863-49f7-b6ba-34a80799550c/resourcegroups/workshoplcl-rg/workspaces/workshoplcl\", \"run_id\": \"Workshop-amlcompute_1602582161_46313f6a\", \"run_properties\": {\"run_id\": \"Workshop-amlcompute_1602582161_46313f6a\", \"created_utc\": \"2020-10-13T09:42:47.819537Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"03322f09-e6b5-428a-b8a7-875deafbfd44\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"Type\": \"test\", \"Langage\": \"Python\", \"Framework\": \"Scikit-Learn\", \"Team\": \"DataScience\", \"Pays\": \"France\", \"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":1}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2020-10-13T09:53:06.664352Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/20_image_build_log.txt\": \"https://workshoplcl3468771077.blob.core.windows.net/azureml/ExperimentRun/dcid.Workshop-amlcompute_1602582161_46313f6a/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=cy%2B6nkQIBLPcNr57bkNHRmMT0bcKgHVuWo4NJLn%2Bw7U%3D&st=2020-10-13T09%3A43%3A01Z&se=2020-10-13T17%3A53%3A01Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_89a740fde66671fb6cbc40857379dc2c5b625d649f2027cfea1bbc63c0f024ee_d.txt\": \"https://workshoplcl3468771077.blob.core.windows.net/azureml/ExperimentRun/dcid.Workshop-amlcompute_1602582161_46313f6a/azureml-logs/55_azureml-execution-tvmps_89a740fde66671fb6cbc40857379dc2c5b625d649f2027cfea1bbc63c0f024ee_d.txt?sv=2019-02-02&sr=b&sig=ACWrlqKL2603TXSIIBI83ReCuKDwQaQDWne%2Fipnd2As%3D&st=2020-10-13T09%3A43%3A01Z&se=2020-10-13T17%3A53%3A01Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_89a740fde66671fb6cbc40857379dc2c5b625d649f2027cfea1bbc63c0f024ee_d.txt\": \"https://workshoplcl3468771077.blob.core.windows.net/azureml/ExperimentRun/dcid.Workshop-amlcompute_1602582161_46313f6a/azureml-logs/65_job_prep-tvmps_89a740fde66671fb6cbc40857379dc2c5b625d649f2027cfea1bbc63c0f024ee_d.txt?sv=2019-02-02&sr=b&sig=GrLoNgRUFMk7VE3yEM2hpOvcTv6Zm1dj%2FQvSGJ6R%2BxQ%3D&st=2020-10-13T09%3A43%3A01Z&se=2020-10-13T17%3A53%3A01Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://workshoplcl3468771077.blob.core.windows.net/azureml/ExperimentRun/dcid.Workshop-amlcompute_1602582161_46313f6a/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=0l5J5Bu0EdDJrZrZjMsetxGn%2Br7Vm0aXcM%2Bm6joguuo%3D&st=2020-10-13T09%3A43%3A01Z&se=2020-10-13T17%3A53%3A01Z&sp=r\", \"azureml-logs/75_job_post-tvmps_89a740fde66671fb6cbc40857379dc2c5b625d649f2027cfea1bbc63c0f024ee_d.txt\": \"https://workshoplcl3468771077.blob.core.windows.net/azureml/ExperimentRun/dcid.Workshop-amlcompute_1602582161_46313f6a/azureml-logs/75_job_post-tvmps_89a740fde66671fb6cbc40857379dc2c5b625d649f2027cfea1bbc63c0f024ee_d.txt?sv=2019-02-02&sr=b&sig=cB035P3jlHT1QiX7JRRWRd5bP0z08mLfev957Wk%2BSu8%3D&st=2020-10-13T09%3A43%3A01Z&se=2020-10-13T17%3A53%3A01Z&sp=r\", \"azureml-logs/process_info.json\": \"https://workshoplcl3468771077.blob.core.windows.net/azureml/ExperimentRun/dcid.Workshop-amlcompute_1602582161_46313f6a/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=4l90h023vFqiVqzj1kaWHIZYB%2BbH0ioidYFCoe72bXc%3D&st=2020-10-13T09%3A43%3A01Z&se=2020-10-13T17%3A53%3A01Z&sp=r\", \"azureml-logs/process_status.json\": \"https://workshoplcl3468771077.blob.core.windows.net/azureml/ExperimentRun/dcid.Workshop-amlcompute_1602582161_46313f6a/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=sLpUPKL4y37GS5IO4ctxqcREf6MAhO%2FjNmqmz2eFWWs%3D&st=2020-10-13T09%3A43%3A01Z&se=2020-10-13T17%3A53%3A01Z&sp=r\", \"logs/azureml/108_azureml.log\": \"https://workshoplcl3468771077.blob.core.windows.net/azureml/ExperimentRun/dcid.Workshop-amlcompute_1602582161_46313f6a/logs/azureml/108_azureml.log?sv=2019-02-02&sr=b&sig=h6AkeZja%2B1yVO3D0iveLGDpAOF%2B4%2FVlBXlUsuFfu1VA%3D&st=2020-10-13T09%3A43%3A01Z&se=2020-10-13T17%3A53%3A01Z&sp=r\", \"logs/azureml/job_prep_azureml.log\": \"https://workshoplcl3468771077.blob.core.windows.net/azureml/ExperimentRun/dcid.Workshop-amlcompute_1602582161_46313f6a/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=r2CQ967Vreh0AGA7xxfE1ogY53zw%2FOw3j2mBvfbiRkw%3D&st=2020-10-13T09%3A43%3A01Z&se=2020-10-13T17%3A53%3A01Z&sp=r\", \"logs/azureml/job_release_azureml.log\": \"https://workshoplcl3468771077.blob.core.windows.net/azureml/ExperimentRun/dcid.Workshop-amlcompute_1602582161_46313f6a/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=KP61JQzf9q7Hi1Jn7W%2FvYAvNuoduOxt6g2NXui3yglE%3D&st=2020-10-13T09%3A43%3A01Z&se=2020-10-13T17%3A53%3A01Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/job_prep_azureml.log\", \"logs/azureml/job_release_azureml.log\"], [\"azureml-logs/20_image_build_log.txt\"], [\"azureml-logs/55_azureml-execution-tvmps_89a740fde66671fb6cbc40857379dc2c5b625d649f2027cfea1bbc63c0f024ee_d.txt\"], [\"azureml-logs/65_job_prep-tvmps_89a740fde66671fb6cbc40857379dc2c5b625d649f2027cfea1bbc63c0f024ee_d.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"azureml-logs/75_job_post-tvmps_89a740fde66671fb6cbc40857379dc2c5b625d649f2027cfea1bbc63c0f024ee_d.txt\"], [\"logs/azureml/108_azureml.log\"]], \"run_duration\": \"0:10:18\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"alpha\", \"run_id\": \"Workshop-amlcompute_1602582161_46313f6a\", \"categories\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], \"series\": [{\"data\": [0.0, 0.05, 0.1, 0.15000000000000002, 0.2, 0.25, 0.30000000000000004, 0.35000000000000003, 0.4, 0.45, 0.5, 0.55, 0.6000000000000001, 0.65, 0.7000000000000001, 0.75, 0.8, 0.8500000000000001, 0.9, 0.9500000000000001]}]}, {\"name\": \"mse\", \"run_id\": \"Workshop-amlcompute_1602582161_46313f6a\", \"categories\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], \"series\": [{\"data\": [3424.3166882137343, 3408.9153122589296, 3372.649627810032, 3345.14964347419, 3325.294679467878, 3311.5562509289744, 3302.6736334017264, 3297.658733944204, 3295.74106435581, 3296.316884705676, 3298.9096058070622, 3303.140055527517, 3308.7042707723226, 3315.3568399622573, 3322.898314903962, 3331.1656169285875, 3340.024662032161, 3349.364644348603, 3359.093569748443, 3369.1347399130477]}]}], \"run_logs\": \"2020-10-13 09:52:31,819|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True, 'only_in_process_features': True, 'skip_track_logs_dir': True}, track_folders: None, deny_list: None, directories_to_watch: []\\n2020-10-13 09:52:31,821|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: batchai\\n2020-10-13 09:52:31,830|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2020-10-13 09:52:31,830|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2020-10-13 09:52:32,203|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7ff10768fbf8> for run source azureml.scriptrun\\n2020-10-13 09:52:32,238|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2020-10-13 09:52:32,246|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2020-10-13 09:52:32,246|azureml.core.authentication|DEBUG|Time to expire 1813814.753372 seconds\\n2020-10-13 09:52:32,246|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2020-10-13 09:52:32,246|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2020-10-13 09:52:32,247|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2020-10-13 09:52:32,247|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2020-10-13 09:52:32,247|azureml._restclient.clientbase|DEBUG|ClientBase: Calling get with url None\\n2020-10-13 09:52:32,306|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2020-10-13 09:52:32,306|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2020-10-13 09:52:32,307|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2020-10-13 09:52:32,357|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.RunClient.get-async:False|DEBUG|[START]\\n2020-10-13 09:52:32,357|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}\\n2020-10-13 09:52:32,448|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.RunClient.get-async:False|DEBUG|[STOP]\\n2020-10-13 09:52:32,449|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': '03322f09-e6b5-428a-b8a7-875deafbfd44', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2020-10-13 09:52:32,449|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2020-10-13 09:52:32,449|azureml|WARNING|Could not import azureml.mlflow or azureml.contrib.mlflow mlflow APIs will not run against AzureML services.  Add azureml-mlflow as a conda dependency for the run if this behavior is desired\\n2020-10-13 09:52:32,450|azureml.WorkerPool|DEBUG|[START]\\n2020-10-13 09:52:32,450|azureml.SendRunKillSignal|DEBUG|[START]\\n2020-10-13 09:52:32,450|azureml.RunStatusContext|DEBUG|[START]\\n2020-10-13 09:52:32,450|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunContextManager.RunStatusContext|DEBUG|[START]\\n2020-10-13 09:52:32,450|azureml.MetricsClient|DEBUG|[START]\\n2020-10-13 09:52:32,450|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient|DEBUG|[START]\\n2020-10-13 09:52:32,450|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2020-10-13 09:52:32,450|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2020-10-13 09:52:32,451|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/workshoplcl/azureml/workshop-amlcompute_1602582161_46313f6a/mounts/workspaceblobstore/azureml/Workshop-amlcompute_1602582161_46313f6a\\n2020-10-13 09:52:32,451|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2020-10-13 09:52:32,451|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /mnt/batch/tasks/shared/LS_root/jobs/workshoplcl/azureml/workshop-amlcompute_1602582161_46313f6a/mounts/workspaceblobstore/azureml/Workshop-amlcompute_1602582161_46313f6a\\n2020-10-13 09:52:39,571|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2020-10-13 09:52:39,572|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2020-10-13 09:52:39,572|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2020-10-13 09:52:39,572|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2020-10-13 09:52:39,572|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2020-10-13 09:52:39,573|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2020-10-13 09:52:39,573|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2020-10-13 09:52:39,585|azureml._run_impl.run_history_facade|DEBUG|Created a static thread pool for RunHistoryFacade class\\n2020-10-13 09:52:39,612|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.RunClient.get-async:False|DEBUG|[START]\\n2020-10-13 09:52:39,612|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}\\n2020-10-13 09:52:39,720|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.RunClient.get-async:False|DEBUG|[STOP]\\n2020-10-13 09:52:39,721|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': '03322f09-e6b5-428a-b8a7-875deafbfd44', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2020-10-13 09:52:39,721|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2020-10-13 09:52:39,811|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2020-10-13 09:52:39,818|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2020-10-13 09:52:39,820|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2020-10-13 09:52:40,821|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2020-10-13 09:52:40,821|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2020-10-13 09:52:40,822|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 20.\\n2020-10-13 09:52:40,822|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2020-10-13 09:52:40,822|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2020-10-13 09:52:40,822|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2020-10-13 09:52:40,822|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2020-10-13 09:52:40,822|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2020-10-13 09:52:40,822|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2020-10-13 09:52:40,822|azureml._restclient.clientbase.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2020-10-13 09:52:40,823|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 20 values.\\n2020-10-13 09:52:40,823|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2020-10-13 09:52:40,823|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 0__log_batch_v2 to queue of approximate size: 0\\n2020-10-13 09:52:40,823|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.post_run_metrics-async:False|DEBUG|[START]\\n2020-10-13 09:52:40,823|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling post_run_metrics with url /metric/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/runs/{runId}/batch\\n2020-10-13 09:52:40,983|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.post_run_metrics-async:False|DEBUG|[STOP]\\n2020-10-13 09:52:41,073|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2020-10-13 09:52:41,073|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2020-10-13 09:52:41,073|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2020-10-13 09:52:41,073|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Waiting on task: 0__handle_batch.\\n1 tasks left. Current duration of flush 0.0001609325408935547 seconds.\\n\\n2020-10-13 09:52:41,073|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2020-10-13 09:52:41,822|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2020-10-13 09:52:41,822|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2020-10-13 09:52:41,822|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 20.\\n2020-10-13 09:52:41,822|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2020-10-13 09:52:41,823|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2020-10-13 09:52:41,823|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2020-10-13 09:52:41,823|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2020-10-13 09:52:41,823|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2020-10-13 09:52:41,823|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2020-10-13 09:52:41,823|azureml._restclient.clientbase.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2020-10-13 09:52:41,824|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 20 values.\\n2020-10-13 09:52:41,824|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.post_run_metrics-async:False|DEBUG|[START]\\n2020-10-13 09:52:41,824|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling post_run_metrics with url /metric/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/runs/{runId}/batch\\n2020-10-13 09:52:41,833|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.1__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2020-10-13 09:52:41,834|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 1__log_batch_v2 to queue of approximate size: 1\\n2020-10-13 09:52:41,956|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.post_run_metrics-async:False|DEBUG|[STOP]\\n2020-10-13 09:52:42,074|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2020-10-13 09:52:42,074|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2020-10-13 09:52:42,074|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2020-10-13 09:52:42,074|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Waiting on task: 0__handle_batch.\\n1 tasks left. Current duration of flush 0.00011324882507324219 seconds.\\n\\n2020-10-13 09:52:42,074|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2020-10-13 09:52:46,249|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2020-10-13 09:52:46,249|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/workshoplcl/azureml/workshop-amlcompute_1602582161_46313f6a/mounts/workspaceblobstore/azureml/Workshop-amlcompute_1602582161_46313f6a\\n2020-10-13 09:52:46,249|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /mnt/batch/tasks/shared/LS_root/jobs/workshoplcl/azureml/workshop-amlcompute_1602582161_46313f6a/mounts/workspaceblobstore/azureml/Workshop-amlcompute_1602582161_46313f6a to /mnt/batch/tasks/shared/LS_root/jobs/workshoplcl/azureml/workshop-amlcompute_1602582161_46313f6a/mounts/workspaceblobstore/azureml/Workshop-amlcompute_1602582161_46313f6a\\n2020-10-13 09:52:46,249|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /mnt/batch/tasks/shared/LS_root/jobs/workshoplcl/azureml/workshop-amlcompute_1602582161_46313f6a/mounts/workspaceblobstore/azureml/Workshop-amlcompute_1602582161_46313f6a\\n2020-10-13 09:52:46,250|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2020-10-13 09:52:46,250|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2020-10-13 09:52:46,250|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2020-10-13 09:52:46,250|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2020-10-13 09:52:46,250|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2020-10-13 09:52:46,250|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2020-10-13 09:52:46,251|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-10-13 09:52:46,251|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2020-10-13 09:52:46,251|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2020-10-13 09:52:46,251|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2020-10-13 09:52:46,251|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-10-13 09:52:46,251|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2020-10-13 09:52:46,251|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2020-10-13 09:52:46,252|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2020-10-13 09:52:46,252|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-10-13 09:52:46,253|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2020-10-13 09:52:46,253|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2020-10-13 09:52:46,253|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2020-10-13 09:52:46,253|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-10-13 09:52:46,253|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2020-10-13 09:52:46,253|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2020-10-13 09:52:46,253|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2020-10-13 09:52:46,552|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2020-10-13 09:52:46,552|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient|DEBUG|[STOP]\\n2020-10-13 09:52:46,553|azureml.MetricsClient|DEBUG|[STOP]\\n2020-10-13 09:52:46,553|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2020-10-13 09:52:46,553|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-10-13 09:52:46,553|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2020-10-13 09:52:46,553|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2020-10-13 09:52:46,553|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2020-10-13 09:52:46,554|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-10-13 09:52:46,554|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-10-13 09:52:46,554|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2020-10-13 09:52:46,554|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2020-10-13 09:52:46,554|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2020-10-13 09:52:46,554|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-10-13 09:52:46,554|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2020-10-13 09:52:46,555|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2020-10-13 09:52:46,555|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2020-10-13 09:52:46,650|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2020-10-13 09:52:46,650|azureml.RunStatusContext|DEBUG|[STOP]\\n2020-10-13 09:52:46,650|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2020-10-13 09:52:46,650|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-10-13 09:52:46,651|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300.0 is different from task queue timeout 120, using flush timeout\\n2020-10-13 09:52:46,651|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300.0 seconds on tasks: [].\\n2020-10-13 09:52:46,651|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2020-10-13 09:52:46,651|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-10-13 09:52:46,651|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-10-13 09:52:46,651|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300.0 is different from task queue timeout 120, using flush timeout\\n2020-10-13 09:52:46,651|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300.0 seconds on tasks: [].\\n2020-10-13 09:52:46,651|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2020-10-13 09:52:46,651|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-10-13 09:52:46,652|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2020-10-13 09:52:46,652|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2020-10-13 09:52:46,652|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2020-10-13 09:52:46,779|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2020-10-13 09:52:46,779|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2020-10-13 09:52:46,779|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2020-10-13 09:52:46,779|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2020-10-13 09:52:46,780|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2020-10-13 09:52:46,780|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-10-13 09:52:46,780|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300.0 is different from task queue timeout 120, using flush timeout\\n2020-10-13 09:52:46,780|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300.0 seconds on tasks: [].\\n2020-10-13 09:52:46,780|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2020-10-13 09:52:46,780|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-10-13 09:52:46,780|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-10-13 09:52:46,780|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300.0 is different from task queue timeout 120, using flush timeout\\n2020-10-13 09:52:46,781|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300.0 seconds on tasks: [AsyncTask(0__log_batch_v2), AsyncTask(1__log_batch_v2)].\\n2020-10-13 09:52:46,781|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[START]\\n2020-10-13 09:52:46,781|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\n2020-10-13 09:52:46,781|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[STOP]\\n2020-10-13 09:52:46,781|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.1__log_batch_v2.WaitingTask|DEBUG|[START]\\n2020-10-13 09:52:46,781|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.1__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\n2020-10-13 09:52:46,781|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.1__log_batch_v2.WaitingTask|DEBUG|[STOP]\\n2020-10-13 09:52:46,781|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2020-10-13 09:52:46,781|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-10-13 09:52:46,782|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2020-10-13 09:52:46,782|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2020-10-13 09:52:46,782|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2020-10-13 09:52:46,874|azureml._SubmittedRun#Workshop-amlcompute_1602582161_46313f6a.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2020-10-13 09:52:46,875|azureml.SendRunKillSignal|DEBUG|[STOP]\\n2020-10-13 09:52:46,875|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[START]\\n2020-10-13 09:52:46,875|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[STOP]\\n2020-10-13 09:52:46,875|azureml.WorkerPool|DEBUG|[STOP]\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.15.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Informations additionnelles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **run.get_details** pour suivre **l'avancement du run**. <br>Si le cluster est inactif, cela peut nécessiter + de temps de traitement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Completed'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statut du run\n",
    "run.get_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runId': 'Workshop-amlcompute_1602582161_46313f6a',\n",
       " 'target': 'cpuclusterd2v2',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-10-13T09:49:25.688789Z',\n",
       " 'endTimeUtc': '2020-10-13T09:53:06.664352Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': '03322f09-e6b5-428a-b8a7-875deafbfd44',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'train_aml.py',\n",
       "  'command': [],\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': [],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'cpuclusterd2v2',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'outputData': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 1,\n",
       "  'priority': None,\n",
       "  'environment': {'name': 'myenv',\n",
       "   'version': 'Autosave_2020-10-13T09:42:45Z_daf56b1b',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults~=1.15.0']},\n",
       "      'scikit-learn==0.20.3'],\n",
       "     'name': 'azureml_86b5e655fc4ec59671b08beb8f65818c'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200821.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': None,\n",
       "   'frameworkImage': None,\n",
       "   'imageVersion': None,\n",
       "   'location': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'globalJobDispatcher': {'vmSize': []}},\n",
       " 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://workshoplcl3468771077.blob.core.windows.net/azureml/ExperimentRun/dcid.Workshop-amlcompute_1602582161_46313f6a/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=cy%2B6nkQIBLPcNr57bkNHRmMT0bcKgHVuWo4NJLn%2Bw7U%3D&st=2020-10-13T09%3A43%3A01Z&se=2020-10-13T17%3A53%3A01Z&sp=r',\n",
       "  'azureml-logs/55_azureml-execution-tvmps_89a740fde66671fb6cbc40857379dc2c5b625d649f2027cfea1bbc63c0f024ee_d.txt': 'https://workshoplcl3468771077.blob.core.windows.net/azureml/ExperimentRun/dcid.Workshop-amlcompute_1602582161_46313f6a/azureml-logs/55_azureml-execution-tvmps_89a740fde66671fb6cbc40857379dc2c5b625d649f2027cfea1bbc63c0f024ee_d.txt?sv=2019-02-02&sr=b&sig=ACWrlqKL2603TXSIIBI83ReCuKDwQaQDWne%2Fipnd2As%3D&st=2020-10-13T09%3A43%3A01Z&se=2020-10-13T17%3A53%3A01Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_89a740fde66671fb6cbc40857379dc2c5b625d649f2027cfea1bbc63c0f024ee_d.txt': 'https://workshoplcl3468771077.blob.core.windows.net/azureml/ExperimentRun/dcid.Workshop-amlcompute_1602582161_46313f6a/azureml-logs/65_job_prep-tvmps_89a740fde66671fb6cbc40857379dc2c5b625d649f2027cfea1bbc63c0f024ee_d.txt?sv=2019-02-02&sr=b&sig=GrLoNgRUFMk7VE3yEM2hpOvcTv6Zm1dj%2FQvSGJ6R%2BxQ%3D&st=2020-10-13T09%3A43%3A01Z&se=2020-10-13T17%3A53%3A01Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://workshoplcl3468771077.blob.core.windows.net/azureml/ExperimentRun/dcid.Workshop-amlcompute_1602582161_46313f6a/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=0l5J5Bu0EdDJrZrZjMsetxGn%2Br7Vm0aXcM%2Bm6joguuo%3D&st=2020-10-13T09%3A43%3A01Z&se=2020-10-13T17%3A53%3A01Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_89a740fde66671fb6cbc40857379dc2c5b625d649f2027cfea1bbc63c0f024ee_d.txt': 'https://workshoplcl3468771077.blob.core.windows.net/azureml/ExperimentRun/dcid.Workshop-amlcompute_1602582161_46313f6a/azureml-logs/75_job_post-tvmps_89a740fde66671fb6cbc40857379dc2c5b625d649f2027cfea1bbc63c0f024ee_d.txt?sv=2019-02-02&sr=b&sig=cB035P3jlHT1QiX7JRRWRd5bP0z08mLfev957Wk%2BSu8%3D&st=2020-10-13T09%3A43%3A01Z&se=2020-10-13T17%3A53%3A01Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://workshoplcl3468771077.blob.core.windows.net/azureml/ExperimentRun/dcid.Workshop-amlcompute_1602582161_46313f6a/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=4l90h023vFqiVqzj1kaWHIZYB%2BbH0ioidYFCoe72bXc%3D&st=2020-10-13T09%3A43%3A01Z&se=2020-10-13T17%3A53%3A01Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://workshoplcl3468771077.blob.core.windows.net/azureml/ExperimentRun/dcid.Workshop-amlcompute_1602582161_46313f6a/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=sLpUPKL4y37GS5IO4ctxqcREf6MAhO%2FjNmqmz2eFWWs%3D&st=2020-10-13T09%3A43%3A01Z&se=2020-10-13T17%3A53%3A01Z&sp=r',\n",
       "  'logs/azureml/108_azureml.log': 'https://workshoplcl3468771077.blob.core.windows.net/azureml/ExperimentRun/dcid.Workshop-amlcompute_1602582161_46313f6a/logs/azureml/108_azureml.log?sv=2019-02-02&sr=b&sig=h6AkeZja%2B1yVO3D0iveLGDpAOF%2B4%2FVlBXlUsuFfu1VA%3D&st=2020-10-13T09%3A43%3A01Z&se=2020-10-13T17%3A53%3A01Z&sp=r',\n",
       "  'logs/azureml/job_prep_azureml.log': 'https://workshoplcl3468771077.blob.core.windows.net/azureml/ExperimentRun/dcid.Workshop-amlcompute_1602582161_46313f6a/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=r2CQ967Vreh0AGA7xxfE1ogY53zw%2FOw3j2mBvfbiRkw%3D&st=2020-10-13T09%3A43%3A01Z&se=2020-10-13T17%3A53%3A01Z&sp=r',\n",
       "  'logs/azureml/job_release_azureml.log': 'https://workshoplcl3468771077.blob.core.windows.net/azureml/ExperimentRun/dcid.Workshop-amlcompute_1602582161_46313f6a/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=KP61JQzf9q7Hi1Jn7W%2FvYAvNuoduOxt6g2NXui3yglE%3D&st=2020-10-13T09%3A43%3A01Z&se=2020-10-13T17%3A53%3A01Z&sp=r'}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Détails du run\n",
    "run.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'nodeId': 'tvmps_89a740fde66671fb6cbc40857379dc2c5b625d649f2027cfea1bbc63c0f024ee_d',\n",
       "  'port': 50000,\n",
       "  'publicIpAddress': '51.105.167.166',\n",
       "  'privateIpAddress': '10.0.0.4',\n",
       "  'nodeState': 'idle'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statut\n",
    "cpu_cluster.list_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Pour voir les métriques de l'expérimentation (uniquement en fin de run). <br>Les métriques sont aussi visibles dans le portail Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liste des métriques :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': [0.0,\n",
       "  0.05,\n",
       "  0.1,\n",
       "  0.15000000000000002,\n",
       "  0.2,\n",
       "  0.25,\n",
       "  0.30000000000000004,\n",
       "  0.35000000000000003,\n",
       "  0.4,\n",
       "  0.45,\n",
       "  0.5,\n",
       "  0.55,\n",
       "  0.6000000000000001,\n",
       "  0.65,\n",
       "  0.7000000000000001,\n",
       "  0.75,\n",
       "  0.8,\n",
       "  0.8500000000000001,\n",
       "  0.9,\n",
       "  0.9500000000000001],\n",
       " 'mse': [3424.3166882137343,\n",
       "  3408.9153122589296,\n",
       "  3372.649627810032,\n",
       "  3345.14964347419,\n",
       "  3325.294679467878,\n",
       "  3311.5562509289744,\n",
       "  3302.6736334017264,\n",
       "  3297.658733944204,\n",
       "  3295.74106435581,\n",
       "  3296.316884705676,\n",
       "  3298.9096058070622,\n",
       "  3303.140055527517,\n",
       "  3308.7042707723226,\n",
       "  3315.3568399622573,\n",
       "  3322.898314903962,\n",
       "  3331.1656169285875,\n",
       "  3340.024662032161,\n",
       "  3349.364644348603,\n",
       "  3359.093569748443,\n",
       "  3369.1347399130477]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Liste des métriques :\")\n",
    "run.get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Informations sur le compute server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status du cluster :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'currentNodeCount': 1,\n",
       " 'targetNodeCount': 1,\n",
       " 'nodeStateCounts': {'preparingNodeCount': 0,\n",
       "  'runningNodeCount': 0,\n",
       "  'idleNodeCount': 1,\n",
       "  'unusableNodeCount': 0,\n",
       "  'leavingNodeCount': 0,\n",
       "  'preemptedNodeCount': 0},\n",
       " 'allocationState': 'Steady',\n",
       " 'allocationStateTransitionTime': '2020-10-13T09:39:58.164000+00:00',\n",
       " 'errors': None,\n",
       " 'creationTime': '2020-10-13T09:38:22.248494+00:00',\n",
       " 'modifiedTime': '2020-10-13T09:38:37.962911+00:00',\n",
       " 'provisioningState': 'Succeeded',\n",
       " 'provisioningStateTransitionTime': None,\n",
       " 'scaleSettings': {'minNodeCount': 1,\n",
       "  'maxNodeCount': 4,\n",
       "  'nodeIdleTimeBeforeScaleDown': 'PT120S'},\n",
       " 'vmPriority': 'Dedicated',\n",
       " 'vmSize': 'STANDARD_D2_V2'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Status du cluster :\")\n",
    "cpu_cluster.get_status().serialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noeuds du cluster :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'nodeId': 'tvmps_89a740fde66671fb6cbc40857379dc2c5b625d649f2027cfea1bbc63c0f024ee_d',\n",
       "  'port': 50000,\n",
       "  'publicIpAddress': '51.105.167.166',\n",
       "  'privateIpAddress': '10.0.0.4',\n",
       "  'nodeState': 'idle'}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Noeuds du cluster :\")\n",
    "cpu_cluster.list_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On peut changer la configuration du compute server :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_cluster.update(min_nodes=0) # On passe à 0 min node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'currentNodeCount': 1,\n",
       " 'targetNodeCount': 1,\n",
       " 'nodeStateCounts': {'preparingNodeCount': 0,\n",
       "  'runningNodeCount': 0,\n",
       "  'idleNodeCount': 1,\n",
       "  'unusableNodeCount': 0,\n",
       "  'leavingNodeCount': 0,\n",
       "  'preemptedNodeCount': 0},\n",
       " 'allocationState': 'Steady',\n",
       " 'allocationStateTransitionTime': '2020-10-13T09:39:58.164000+00:00',\n",
       " 'errors': None,\n",
       " 'creationTime': '2020-10-13T09:38:22.248494+00:00',\n",
       " 'modifiedTime': '2020-10-13T09:54:41.274807+00:00',\n",
       " 'provisioningState': 'Succeeded',\n",
       " 'provisioningStateTransitionTime': None,\n",
       " 'scaleSettings': {'minNodeCount': 0,\n",
       "  'maxNodeCount': 4,\n",
       "  'nodeIdleTimeBeforeScaleDown': 'PT120S'},\n",
       " 'vmPriority': 'Dedicated',\n",
       " 'vmSize': 'STANDARD_D2_V2'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_cluster.get_status().serialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_cluster.update(max_nodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_cluster.update(idle_seconds_before_scaledown=1200) # On change le timeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status du cluster\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'currentNodeCount': 1,\n",
       " 'targetNodeCount': 1,\n",
       " 'nodeStateCounts': {'preparingNodeCount': 0,\n",
       "  'runningNodeCount': 0,\n",
       "  'idleNodeCount': 1,\n",
       "  'unusableNodeCount': 0,\n",
       "  'leavingNodeCount': 0,\n",
       "  'preemptedNodeCount': 0},\n",
       " 'allocationState': 'Steady',\n",
       " 'allocationStateTransitionTime': '2020-10-13T09:39:58.164000+00:00',\n",
       " 'errors': None,\n",
       " 'creationTime': '2020-10-13T09:38:22.248494+00:00',\n",
       " 'modifiedTime': '2020-10-13T09:54:49.548267+00:00',\n",
       " 'provisioningState': 'Succeeded',\n",
       " 'provisioningStateTransitionTime': None,\n",
       " 'scaleSettings': {'minNodeCount': 0,\n",
       "  'maxNodeCount': 10,\n",
       "  'nodeIdleTimeBeforeScaleDown': 'PT1200S'},\n",
       " 'vmPriority': 'Dedicated',\n",
       " 'vmSize': 'STANDARD_D2_V2'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Status du cluster\")\n",
    "cpu_cluster.get_status().serialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_cluster.update(min_nodes=2, max_nodes=4, idle_seconds_before_scaledown=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppression du compute server :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour supprimer le compute server\n",
    "cpu_cluster.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpuclusterd2v2  -  AmlCompute  -  Deleting\n",
      "nbookinstance  -  ComputeInstance  -  Succeeded\n",
      "monclustercpu  -  AmlCompute  -  Succeeded\n",
      "cpucluster  -  AmlCompute  -  Succeeded\n",
      "cpuclusterd2  -  AmlCompute  -  Succeeded\n",
      "clustergpu  -  AmlCompute  -  Succeeded\n"
     ]
    }
   ],
   "source": [
    "compute_targets = ws.compute_targets\n",
    "for name, ct in compute_targets.items():\n",
    "    print(name, \" - \" , ct.type, \" - \", ct.provisioning_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/retkowsky/images/blob/master/Powered-by-MS-Azure-logo-v2.png?raw=true\" height=\"300\" width=\"300\">"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "nigup"
   }
  ],
  "category": "training",
  "compute": [
   "AML Compute"
  ],
  "datasets": [
   "Diabetes"
  ],
  "deployment": [
   "None"
  ],
  "exclude_from_index": false,
  "framework": [
   "None"
  ],
  "friendly_name": "Train on Azure Machine Learning Compute",
  "index_order": 1,
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "tags": [
   "None"
  ],
  "task": "Submit a run on Azure Machine Learning Compute."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
